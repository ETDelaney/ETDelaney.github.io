---
layout: post
title: Low-Frequency Conditioning
---
When pumping the spectra of measured interferometric data through the modelling engine, the modelled data does not produce the same output. This may be attributed to many processes - modelling in the 2D domain (Earth is 3D even for Scholte waves), absorbing boundaries, the fact that the measured data is actually a convolution of the Earth and the source (perhaps we need to deconvolve), etc. A simple fix could be to knock out the frequencies post-modelling, but since we need the recorded wavefield to compute the gradient on-the-fly... then the recorded wavefield would still have the low-frequency noise. Luckily, we also compute and store the wavefield's Green function in the frequency domain. This means we can knock it out then and there.

<hr>

### Modelled versus Measured
The SWIM array itself has 172 receivers. We will look at receivers 001 and 036. To initially match the modelled with the measured, we used the following source-time function:

```Matlab
stf = -1500*1.0e9 * ones(1, nt);
```

Notice that, as seen from previous post, since we are using first-order pde's to model wave propagation, then we must insert a heavy-side step function to give us G(t). Had we used a delta-pulse, then we would have modelled dG/dt.

You should also notice that we also had to apply a phase rotation of 180 degrees to get a match. I have not looked into this, but it could be related to not accounting for assymetric imaginary terms that pop up in the correlation derivation - or more likely, to the fact that the measured data is acceleration-acceleration correlations, and I am modelling displacment-displacement correlations for simplicity. Does not really matter, because the $$\omega^2$$ term in the acceleration-acceleration gets knocked out when I bandpass... and furthermore, I can feed the bandpassed measured spectra into the modelling code for the power-spectral density. The only thing to rememeber is the 180 degrees... which may make since implicity if recalling that it is not actually $$\omega^2$$, but rather $$(i\omega)^2$$... when converting between accelerations and displacements... and hence the $$-1$$ pops up.

Now when we look at the modelled (in orange) which is generated by pumping the spectrum of the measured correlated wavefield (001-036) into the code, we see we do not get the same correlation function as the that of the measured wavefield:

  ![_config.yml]({{ site.baseurl }}/images/modelled-versus-measured.PNG)

When looking at the input spectrum and comparing it with the output spectrum, we see there is considerable difference in the low frequency portion:

  ![_config.yml]({{ site.baseurl }}/images/input-output-spectrum.PNG)

### Deconvolve?
As you could see in a previous figure, I had used a homogeneous medium to model the correlation functions. However, my measured wavefields are not just a function of the noise source, but also Earth structure. Maybe I am feeding it the wrong input spectrum? Or maybe it is the fact the measured wavefield is from the propagation of surface-wave arrivals through a 3D medium, whereas my modelled wavefields are generated through a 2D medium that comes from a cylindrical infinite source that decays away over infinite time.

If such is the case, perhaps it would best to first deconvolve my measured wavefields so that I could only input the power-spectral density of the noise sources. This would described in the following paper (Eq. 11):

[Generalized Interferometry](https://academic.oup.com/gji/article/208/2/603/2447807)

Given that we have assumed some Q, we could then remove the contribution from the Earth and be left with the source-time function's spectrum.

### Absorbing boundaries
Most likely, it is due to the absorbing boundaries. You can read more about this in:

[Avoiding interfometry artifacts when modelling correlations](https://etdelaney.github.io/Avoiding-Artifacts-in-Modelling-Correlations/)

### Be lazy, hammer it with Fourier
Theory is nice, but I would also like to try a more practical approach to this problem. Let us just take the final product and remove the frequencies that should not be there. You could first view the modelled spectrum as such:

```python
# import library and data
import scipy.io
mat = scipy.io.loadmat('correlation_1_36.mat')
data = mat['select_correlation']
t2 = mat['t']
data = np.squeeze(data)
t2 = np.squeeze(t2)

# FFT and flip the vector around so we can plot it
# Amplitudes
f2 = np.fft.fft(data)
fshift2 = np.fft.fftshift(f2)
magnitude_spectrum2 = np.abs(fshift2)

# Frequency indices
freq2 = np.fft.fftfreq(magnitude_spectrum2.size, d=0.025)
freq2 = np.fft.fftshift(freq2)

plt.plot(freq2[600:675],magnitude_spectrum2[600:675]/magnitude_spectrum2.max())
```

You should note that we do have negative frequencies... and even though they are symmetric in amplitudes, they they negative symmetric in phase. Not a big deal... but make sure to knock the negative frequencies as well:

```python
# check out how it looks on the negative frequency side
plt.plot(magnitude_spectrum2[580:620])

# knock these low frequencies out and now look at how the spectrum looks:
fshift2[580:620] = 0
plt.plot(freq2[600:675],magnitude_spectrum2[600:675]/magnitude_spectrum2.max())

# looks good, so let us bring it back to time
test_transform = np.fft.ifftshift(fshift2)
test_transform = np.fft.ifft(test_transform)
plt.plot(t2,np.real(test_transform))
```

So, if we look at the before and after effects of using the FFT hammer, we get the following:

  ![_config.yml]({{ site.baseurl }}/images/before-after-FFT.PNG)

### Calculating the kernel
This is nice. We see there are only marginal differences between the measured and modelled (which are probably attributed to the 2D versus 3D modelling, limitations of a 4th-order spatial/2nd-order time FD setup, and perturbations from the real-Earth structure). These differences are negligible provided that we stick to measuring correlated time differences between the modelled and measured. The wiggles match up so well that we could even avoid having to derive an envelope-based kernel method.

However, we still potentially have a big problem. The calculation of the adjoint requires us to not only inject the modelled correlation function (which we have now corrected in the previous section), but also to backpropagate the recorded wavefield (which has not been corrected).

Without any correction of the recorded wavefield, I get a kernel that looks like (T<0, where synthetic arrives before measured indicated we need to decrease the starting homogenous velocity model 360m/s - we can do this by adding a kernel that increases density):

  ![_config.yml]({{ site.baseurl }}/images/structure-kernel-with-low-fr-noise.PNG)

